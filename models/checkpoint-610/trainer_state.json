{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 610,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08247422680412371,
      "grad_norm": 0.21643047034740448,
      "learning_rate": 2.955737704918033e-05,
      "loss": 0.3759,
      "step": 10
    },
    {
      "epoch": 0.16494845360824742,
      "grad_norm": 0.21262100338935852,
      "learning_rate": 2.9065573770491805e-05,
      "loss": 0.3074,
      "step": 20
    },
    {
      "epoch": 0.24742268041237114,
      "grad_norm": 0.19947297871112823,
      "learning_rate": 2.857377049180328e-05,
      "loss": 0.2369,
      "step": 30
    },
    {
      "epoch": 0.32989690721649484,
      "grad_norm": 0.19266493618488312,
      "learning_rate": 2.8081967213114756e-05,
      "loss": 0.1728,
      "step": 40
    },
    {
      "epoch": 0.41237113402061853,
      "grad_norm": 0.193455308675766,
      "learning_rate": 2.759016393442623e-05,
      "loss": 0.114,
      "step": 50
    },
    {
      "epoch": 0.4948453608247423,
      "grad_norm": 0.13769963383674622,
      "learning_rate": 2.7098360655737704e-05,
      "loss": 0.0581,
      "step": 60
    },
    {
      "epoch": 0.5773195876288659,
      "grad_norm": 0.04936235398054123,
      "learning_rate": 2.660655737704918e-05,
      "loss": 0.0215,
      "step": 70
    },
    {
      "epoch": 0.6597938144329897,
      "grad_norm": 0.029488321393728256,
      "learning_rate": 2.6114754098360654e-05,
      "loss": 0.0108,
      "step": 80
    },
    {
      "epoch": 0.7422680412371134,
      "grad_norm": 0.021473046392202377,
      "learning_rate": 2.562295081967213e-05,
      "loss": 0.0069,
      "step": 90
    },
    {
      "epoch": 0.8247422680412371,
      "grad_norm": 0.016733869910240173,
      "learning_rate": 2.513114754098361e-05,
      "loss": 0.0049,
      "step": 100
    },
    {
      "epoch": 0.9072164948453608,
      "grad_norm": 0.013494172133505344,
      "learning_rate": 2.4639344262295082e-05,
      "loss": 0.0037,
      "step": 110
    },
    {
      "epoch": 0.9896907216494846,
      "grad_norm": 0.011182841844856739,
      "learning_rate": 2.4147540983606556e-05,
      "loss": 0.003,
      "step": 120
    },
    {
      "epoch": 1.065979381443299,
      "grad_norm": 0.00943607185035944,
      "learning_rate": 2.3655737704918033e-05,
      "loss": 0.0024,
      "step": 130
    },
    {
      "epoch": 1.1484536082474226,
      "grad_norm": 0.008316821418702602,
      "learning_rate": 2.3163934426229507e-05,
      "loss": 0.002,
      "step": 140
    },
    {
      "epoch": 1.2309278350515465,
      "grad_norm": 0.007287262007594109,
      "learning_rate": 2.2672131147540987e-05,
      "loss": 0.0017,
      "step": 150
    },
    {
      "epoch": 1.31340206185567,
      "grad_norm": 0.006537029054015875,
      "learning_rate": 2.218032786885246e-05,
      "loss": 0.0015,
      "step": 160
    },
    {
      "epoch": 1.3958762886597937,
      "grad_norm": 0.005806647706776857,
      "learning_rate": 2.1688524590163934e-05,
      "loss": 0.0013,
      "step": 170
    },
    {
      "epoch": 1.4783505154639176,
      "grad_norm": 0.005280618090182543,
      "learning_rate": 2.119672131147541e-05,
      "loss": 0.0012,
      "step": 180
    },
    {
      "epoch": 1.5608247422680412,
      "grad_norm": 0.004780196119099855,
      "learning_rate": 2.0704918032786885e-05,
      "loss": 0.0011,
      "step": 190
    },
    {
      "epoch": 1.6432989690721649,
      "grad_norm": 0.004392835311591625,
      "learning_rate": 2.021311475409836e-05,
      "loss": 0.001,
      "step": 200
    },
    {
      "epoch": 1.7257731958762887,
      "grad_norm": 0.0040479013696312904,
      "learning_rate": 1.972131147540984e-05,
      "loss": 0.0009,
      "step": 210
    },
    {
      "epoch": 1.8082474226804124,
      "grad_norm": 0.0037835082039237022,
      "learning_rate": 1.9229508196721313e-05,
      "loss": 0.0008,
      "step": 220
    },
    {
      "epoch": 1.890721649484536,
      "grad_norm": 0.0035071340389549732,
      "learning_rate": 1.8737704918032787e-05,
      "loss": 0.0007,
      "step": 230
    },
    {
      "epoch": 1.97319587628866,
      "grad_norm": 0.0032397385220974684,
      "learning_rate": 1.8245901639344264e-05,
      "loss": 0.0007,
      "step": 240
    },
    {
      "epoch": 2.049484536082474,
      "grad_norm": 0.0030523466411978006,
      "learning_rate": 1.7754098360655737e-05,
      "loss": 0.0006,
      "step": 250
    },
    {
      "epoch": 2.131958762886598,
      "grad_norm": 0.002861772431060672,
      "learning_rate": 1.726229508196721e-05,
      "loss": 0.0006,
      "step": 260
    },
    {
      "epoch": 2.2144329896907218,
      "grad_norm": 0.002730000065639615,
      "learning_rate": 1.677049180327869e-05,
      "loss": 0.0006,
      "step": 270
    },
    {
      "epoch": 2.296907216494845,
      "grad_norm": 0.0025496147572994232,
      "learning_rate": 1.6278688524590165e-05,
      "loss": 0.0005,
      "step": 280
    },
    {
      "epoch": 2.379381443298969,
      "grad_norm": 0.0024249085690826178,
      "learning_rate": 1.578688524590164e-05,
      "loss": 0.0005,
      "step": 290
    },
    {
      "epoch": 2.461855670103093,
      "grad_norm": 0.0023186407051980495,
      "learning_rate": 1.5295081967213116e-05,
      "loss": 0.0005,
      "step": 300
    },
    {
      "epoch": 2.5443298969072163,
      "grad_norm": 0.0022001471370458603,
      "learning_rate": 1.4803278688524591e-05,
      "loss": 0.0004,
      "step": 310
    },
    {
      "epoch": 2.62680412371134,
      "grad_norm": 0.0021197956521064043,
      "learning_rate": 1.4311475409836067e-05,
      "loss": 0.0004,
      "step": 320
    },
    {
      "epoch": 2.709278350515464,
      "grad_norm": 0.002025000052526593,
      "learning_rate": 1.381967213114754e-05,
      "loss": 0.0004,
      "step": 330
    },
    {
      "epoch": 2.7917525773195875,
      "grad_norm": 0.0019438739400357008,
      "learning_rate": 1.3327868852459017e-05,
      "loss": 0.0004,
      "step": 340
    },
    {
      "epoch": 2.8742268041237113,
      "grad_norm": 0.0018696229672059417,
      "learning_rate": 1.2836065573770493e-05,
      "loss": 0.0004,
      "step": 350
    },
    {
      "epoch": 2.956701030927835,
      "grad_norm": 0.0018065462354570627,
      "learning_rate": 1.2344262295081968e-05,
      "loss": 0.0004,
      "step": 360
    },
    {
      "epoch": 3.0329896907216494,
      "grad_norm": 0.0017488932935521007,
      "learning_rate": 1.1852459016393442e-05,
      "loss": 0.0003,
      "step": 370
    },
    {
      "epoch": 3.1154639175257732,
      "grad_norm": 0.0016859376337379217,
      "learning_rate": 1.1360655737704919e-05,
      "loss": 0.0003,
      "step": 380
    },
    {
      "epoch": 3.197938144329897,
      "grad_norm": 0.0016290764324367046,
      "learning_rate": 1.0868852459016394e-05,
      "loss": 0.0003,
      "step": 390
    },
    {
      "epoch": 3.2804123711340205,
      "grad_norm": 0.0015811983030289412,
      "learning_rate": 1.0377049180327868e-05,
      "loss": 0.0003,
      "step": 400
    },
    {
      "epoch": 3.3628865979381444,
      "grad_norm": 0.0015387262683361769,
      "learning_rate": 9.885245901639345e-06,
      "loss": 0.0003,
      "step": 410
    },
    {
      "epoch": 3.4453608247422682,
      "grad_norm": 0.001499791513197124,
      "learning_rate": 9.39344262295082e-06,
      "loss": 0.0003,
      "step": 420
    },
    {
      "epoch": 3.5278350515463917,
      "grad_norm": 0.001453029690310359,
      "learning_rate": 8.901639344262294e-06,
      "loss": 0.0003,
      "step": 430
    },
    {
      "epoch": 3.6103092783505155,
      "grad_norm": 0.0014355173334479332,
      "learning_rate": 8.409836065573771e-06,
      "loss": 0.0003,
      "step": 440
    },
    {
      "epoch": 3.6927835051546394,
      "grad_norm": 0.001386006479151547,
      "learning_rate": 7.918032786885246e-06,
      "loss": 0.0003,
      "step": 450
    },
    {
      "epoch": 3.775257731958763,
      "grad_norm": 0.0013719969429075718,
      "learning_rate": 7.426229508196722e-06,
      "loss": 0.0003,
      "step": 460
    },
    {
      "epoch": 3.8577319587628867,
      "grad_norm": 0.001336266053840518,
      "learning_rate": 6.934426229508197e-06,
      "loss": 0.0003,
      "step": 470
    },
    {
      "epoch": 3.9402061855670105,
      "grad_norm": 0.0013173166662454605,
      "learning_rate": 6.4426229508196725e-06,
      "loss": 0.0003,
      "step": 480
    },
    {
      "epoch": 4.016494845360825,
      "grad_norm": 0.0013049334520474076,
      "learning_rate": 5.950819672131148e-06,
      "loss": 0.0003,
      "step": 490
    },
    {
      "epoch": 4.098969072164948,
      "grad_norm": 0.0012825707672163844,
      "learning_rate": 5.459016393442623e-06,
      "loss": 0.0002,
      "step": 500
    },
    {
      "epoch": 4.181443298969072,
      "grad_norm": 0.001254746806807816,
      "learning_rate": 4.967213114754099e-06,
      "loss": 0.0002,
      "step": 510
    },
    {
      "epoch": 4.263917525773196,
      "grad_norm": 0.0012461887672543526,
      "learning_rate": 4.475409836065574e-06,
      "loss": 0.0002,
      "step": 520
    },
    {
      "epoch": 4.346391752577319,
      "grad_norm": 0.0012330063618719578,
      "learning_rate": 3.9836065573770485e-06,
      "loss": 0.0002,
      "step": 530
    },
    {
      "epoch": 4.4288659793814436,
      "grad_norm": 0.001217902870848775,
      "learning_rate": 3.4918032786885247e-06,
      "loss": 0.0002,
      "step": 540
    },
    {
      "epoch": 4.511340206185567,
      "grad_norm": 0.0012013799278065562,
      "learning_rate": 3e-06,
      "loss": 0.0002,
      "step": 550
    },
    {
      "epoch": 4.59381443298969,
      "grad_norm": 0.0011919528478756547,
      "learning_rate": 2.5081967213114754e-06,
      "loss": 0.0002,
      "step": 560
    },
    {
      "epoch": 4.676288659793815,
      "grad_norm": 0.0011995225213468075,
      "learning_rate": 2.016393442622951e-06,
      "loss": 0.0002,
      "step": 570
    },
    {
      "epoch": 4.758762886597938,
      "grad_norm": 0.00118353683501482,
      "learning_rate": 1.5245901639344262e-06,
      "loss": 0.0002,
      "step": 580
    },
    {
      "epoch": 4.8412371134020615,
      "grad_norm": 0.0011786841787397861,
      "learning_rate": 1.0327868852459018e-06,
      "loss": 0.0002,
      "step": 590
    },
    {
      "epoch": 4.923711340206186,
      "grad_norm": 0.0011781820794567466,
      "learning_rate": 5.409836065573771e-07,
      "loss": 0.0002,
      "step": 600
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.001187749207019806,
      "learning_rate": 4.918032786885246e-08,
      "loss": 0.0002,
      "step": 610
    }
  ],
  "logging_steps": 10,
  "max_steps": 610,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1616606532748800.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
